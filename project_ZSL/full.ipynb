{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Stitcher:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def stitch(self, imgs, blending_mode = \"linearBlending\", ratio = 0.75):\n",
    "        '''\n",
    "            The main method to stitch image\n",
    "        '''\n",
    "        img_left, img_right = imgs\n",
    "        (hl, wl) = img_left.shape[:2]\n",
    "        (hr, wr) = img_right.shape[:2]\n",
    "        # print(\"Left img size (\", hl, \"*\", wl, \")\")\n",
    "        # print(\"Right img size (\", hr, \"*\", wr, \")\")\n",
    "        \n",
    "        # Step1 - extract the keypoints and features by SIFT detector and descriptor\n",
    "        print(\"Step1 - Extract the keypoints and features by SIFT detector and descriptor...\")\n",
    "        kps_l, features_l = self.detectAndDescribe(img_left)\n",
    "        kps_r, features_r = self.detectAndDescribe(img_right)\n",
    "        \n",
    "        # Step2 - extract the match point with threshold (David Lowe's ratio test)\n",
    "        print(\"Step2 - Extract the match point with threshold (David Lowe's ratio test)...\")\n",
    "        matches_pos = self.matchKeyPoint(kps_l, kps_r, features_l, features_r, ratio)\n",
    "        print(\"The number of matching points:\", len(matches_pos))\n",
    "        \n",
    "        # Step2-2 - draw the img with matching point and their connection line\n",
    "        self.drawMatches([img_left, img_right], matches_pos)\n",
    "        \n",
    "        # Step3 - fit the homography model with RANSAC algorithm\n",
    "        print(\"Step3 - Fit the best homography model with RANSAC algorithm...\")\n",
    "        HomoMat = self.fitHomoMat(matches_pos)\n",
    "        \n",
    "    \n",
    "        # Step4 - Warp image to create panoramic image\n",
    "        print(\"Step4 - Warp image to create panoramic image...\")\n",
    "        warp_img = self.warp([img_left, img_right], HomoMat, blending_mode) \n",
    "        \n",
    "        return warp_img\n",
    "    \n",
    "    def detectAndDescribe(self, img):\n",
    "        '''\n",
    "        The Detector and Descriptor\n",
    "        '''\n",
    "        # SIFT detector and descriptor\n",
    "        sift = cv2.SIFT_create()\n",
    "        kps, features = sift.detectAndCompute(img, None)\n",
    "        \n",
    "        return kps, features\n",
    "\n",
    "    def matchKeyPoint(self, kps_l, kps_r, features_l, features_r, ratio):\n",
    "        match = cv2.BFMatcher(normType=cv2.NORM_L2)\n",
    "        matches = match.knnMatch(features_l, features_r, k=2)\n",
    "        good_match = []\n",
    "        for m, n in matches:\n",
    "            if m.distance < ratio * n.distance:    \n",
    "                good_match.append(m)\n",
    "                \n",
    "        goodMatches = [[m.queryIdx, m.trainIdx] for m in good_match]\n",
    "        goodMatches_pos = []\n",
    "        for (idx, correspondingIdx) in goodMatches: \n",
    "            psA = (int(kps_l[idx].pt[0]), int(kps_l[idx].pt[1]))  # coordinates of the interesting points of img_l\n",
    "            psB = (int(kps_r[correspondingIdx].pt[0]), int(kps_r[correspondingIdx].pt[1]))  # coordinates of the corresponding match\n",
    "            goodMatches_pos.append([psA, psB])\n",
    "            \n",
    "        return goodMatches_pos\n",
    "        \n",
    "\n",
    "        \n",
    "    #     src_pts = np.float32([kps_l[m.queryIdx].pt for m in good_match]).reshape(-1,1,2)\n",
    "    #     dst_pts = np.float32([kps_r[m.trainIdx].pt for m in good_match]).reshape(-1,1,2)\n",
    "\n",
    "    # def matchKeyPoint(self, kps_l, kps_r, features_l, features_r, ratio):\n",
    "    #     '''\n",
    "    #         Match the Keypoints beteewn two image\n",
    "    #     '''\n",
    "    #     Match_idxAndDist = []  # min corresponding index, min distance, seccond min corresponding index, second min distance\n",
    "    #     for i in range(len(features_l)):\n",
    "    #         min_IdxDis = [-1, np.inf]  # record the min corresponding index, min distance\n",
    "    #         secMin_IdxDis = [-1 ,np.inf]  # record the second corresponding min index, min distance\n",
    "    #         for j in range(len(features_r)):\n",
    "    #             dist = np.linalg.norm(features_l[i] - features_r[j])\n",
    "    #             if (min_IdxDis[1] > dist):\n",
    "    #                 secMin_IdxDis = np.copy(min_IdxDis)\n",
    "    #                 min_IdxDis = [j , dist]\n",
    "    #             elif (secMin_IdxDis[1] > dist and secMin_IdxDis[1] != min_IdxDis[1]):\n",
    "    #                 secMin_IdxDis = [j, dist]\n",
    "            \n",
    "    #         Match_idxAndDist.append([min_IdxDis[0], min_IdxDis[1], secMin_IdxDis[0], secMin_IdxDis[1]])\n",
    "\n",
    "    #     # ratio test as per Lowe's paper\n",
    "    #     # reject the point if ||f1 - f2 || / || f1 - f2' || >= ratio, that represent it's ambiguous point\n",
    "\n",
    "    #     goodMatches = []   # every element is the index of the match pair\n",
    "    #     for i in range(len(Match_idxAndDist)):\n",
    "    #         if (Match_idxAndDist[i][1] <= Match_idxAndDist[i][3] * ratio):\n",
    "    #             goodMatches.append((i, Match_idxAndDist[i][0]))\n",
    "            \n",
    "    #     goodMatches_pos = []\n",
    "    #     for (idx, correspondingIdx) in goodMatches: \n",
    "    #         psA = (int(kps_l[idx].pt[0]), int(kps_l[idx].pt[1]))  # coordinates of the interesting points of img_l\n",
    "    #         psB = (int(kps_r[correspondingIdx].pt[0]), int(kps_r[correspondingIdx].pt[1]))  # coordinates of the corresponding match\n",
    "    #         goodMatches_pos.append([psA, psB])\n",
    "            \n",
    "    #     return goodMatches_pos\n",
    "\n",
    "    def drawMatches(self, imgs, matches_pos):\n",
    "            '''\n",
    "                Draw the match points img with keypoints and connection line\n",
    "            '''\n",
    "            \n",
    "            # initialize the output visualization image\n",
    "            img_left, img_right = imgs\n",
    "            (hl, wl) = img_left.shape[:2]\n",
    "            (hr, wr) = img_right.shape[:2]\n",
    "            vis = np.zeros((max(hl, hr), wl + wr, 3), dtype=\"uint8\")\n",
    "            vis[0:hl, 0:wl] = img_left\n",
    "            vis[0:hr, wl:] = img_right\n",
    "            \n",
    "            # Draw the match\n",
    "            for (img_left_pos, img_right_pos) in matches_pos:\n",
    "                    pos_l = img_left_pos\n",
    "                    pos_r = img_right_pos[0] + wl, img_right_pos[1]\n",
    "                    cv2.circle(vis, pos_l, 3, (0, 0, 255), 1)\n",
    "                    cv2.circle(vis, pos_r, 3, (0, 255, 0), 1)\n",
    "                    cv2.line(vis, pos_l, pos_r, (255, 0, 0), 1)\n",
    "                    \n",
    "            # return the visualization\n",
    "            plt.figure(1)\n",
    "            plt.title(\"img with matching points\")\n",
    "            plt.imshow(vis[:,:,::-1])\n",
    "            #cv2.imwrite(\"Feature matching img/matching.jpg\", vis)\n",
    "            \n",
    "            return vis\n",
    "    def fitHomoMat(self, matches_pos):\n",
    "        '''\n",
    "            Fit the best homography model with RANSAC algorithm - noBlending、linearBlending、linearBlendingWithConstant\n",
    "        '''\n",
    "        dstPoints = [] # i.e. left image(destination image)\n",
    "        srcPoints = [] # i.e. right image(source image) \n",
    "        for dstPoint, srcPoint in matches_pos:\n",
    "            dstPoints.append(list(dstPoint)) \n",
    "            srcPoints.append(list(srcPoint))\n",
    "        dstPoints = np.array(dstPoints)\n",
    "        srcPoints = np.array(srcPoints)\n",
    "        \n",
    "        homography = Homography()\n",
    "        \n",
    "        # RANSAC algorithm, selecting the best fit homography\n",
    "        NumSample = len(matches_pos)\n",
    "        threshold = 5.0  \n",
    "        NumIter = 8000\n",
    "        NumRamdomSubSample = 4\n",
    "        MaxInlier = 0\n",
    "        Best_H = None\n",
    "        \n",
    "        for run in range(NumIter):\n",
    "            SubSampleIdx = random.sample(range(NumSample), NumRamdomSubSample) # get the Index of ramdom sampling\n",
    "            H = homography.solve_homography(srcPoints[SubSampleIdx], dstPoints[SubSampleIdx])\n",
    "            \n",
    "            # find the best Homography have the the maximum number of inlier\n",
    "            NumInlier = 0 \n",
    "            for i in range(NumSample):\n",
    "                if i not in SubSampleIdx:\n",
    "                    concateCoor = np.hstack((srcPoints[i], [1])) # add z-axis as 1\n",
    "                    dstCoor = H @ concateCoor.T # calculate the coordination after transform to destination img \n",
    "                    if dstCoor[2] <= 1e-8: # avoid divide zero number, or too small number cause overflow\n",
    "                        continue\n",
    "                    dstCoor = dstCoor / dstCoor[2]\n",
    "                    if (np.linalg.norm(dstCoor[:2] - dstPoints[i]) < threshold):\n",
    "                        NumInlier = NumInlier + 1\n",
    "            if (MaxInlier < NumInlier):\n",
    "                MaxInlier = NumInlier\n",
    "                Best_H = H\n",
    "                \n",
    "        print(\"The Number of Maximum Inlier:\", MaxInlier)\n",
    "        print(Best_H)\n",
    "        coor = np.array([255,333,1])\n",
    "        print(Best_H @ coor)\n",
    "        return Best_H\n",
    "\n",
    "    def warp(self, imgs, HomoMat, blending_mode):\n",
    "            '''\n",
    "            Warp image to create panoramic image\n",
    "            There are three different blending method - noBlending、linearBlending、linearBlendingWithConstant\n",
    "            '''\n",
    "            img_left, img_right = imgs\n",
    "            (hl, wl) = img_left.shape[:2]\n",
    "            (hr, wr) = img_right.shape[:2]\n",
    "            stitch_img = np.zeros( (max(hl, hr), wl + wr, 3), dtype=\"int\") # create the (stitch)big image accroding the imgs height and width \n",
    "            \n",
    "            if (blending_mode == \"noBlending\"):\n",
    "                stitch_img[:hl, :wl] = img_left\n",
    "                \n",
    "            # Transform Right image(the coordination of right image) to destination iamge(the coordination of left image) with HomoMat\n",
    "            inv_H = np.linalg.inv(HomoMat)\n",
    "            for i in range(stitch_img.shape[0]):\n",
    "                for j in range(stitch_img.shape[1]):\n",
    "                    coor = np.array([j, i, 1])\n",
    "                    img_right_coor = inv_H @ coor # the coordination of right image\n",
    "                    img_right_coor /= img_right_coor[2]\n",
    "                    \n",
    "                    # you can try like nearest neighbors or interpolation  \n",
    "                    y, x = int(round(img_right_coor[0])), int(round(img_right_coor[1])) # y for width, x for height\n",
    "                    \n",
    "                    \n",
    "                    # if the computed coordination not in the (hegiht, width) of right image, it's not need to be process \n",
    "                    if (x < 0 or x >= hr or y < 0 or y >= wr):\n",
    "                        continue\n",
    "                    # else we need the tranform for this pixel\n",
    "                    stitch_img[i, j] = img_right[x, y]\n",
    "                \n",
    "            \n",
    "            # create the Blender object to blending the image\n",
    "            blender = Blender()\n",
    "            if (blending_mode == \"linearBlending\"):\n",
    "                stitch_img = blender.linearBlending([img_left, stitch_img])\n",
    "            elif (blending_mode == \"linearBlendingWithConstant\"):\n",
    "                stitch_img = blender.linearBlendingWithConstantWidth([img_left, stitch_img])\n",
    "            \n",
    "            # remove the black border\n",
    "            # stitch_img = self.removeBlackBorder(stitch_img)\n",
    "            \n",
    "            return stitch_img\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Homography:\n",
    "    def solve_homography(self, P, m):\n",
    "        \"\"\"\n",
    "        Solve homography matrix \n",
    "        Args:\n",
    "            P:  Coordinates of the points in the original plane,\n",
    "            m:  Coordinates of the points in the target plane\n",
    "        Returns:\n",
    "            H: Homography matrix \n",
    "        \"\"\"\n",
    "        A = []  \n",
    "        for r in range(len(P)): \n",
    "            #print(m[r, 0])\n",
    "            A.append([-P[r,0], -P[r,1], -1, 0, 0, 0, P[r,0]*m[r,0], P[r,1]*m[r,0], m[r,0]])\n",
    "            A.append([0, 0, 0, -P[r,0], -P[r,1], -1, P[r,0]*m[r,1], P[r,1]*m[r,1], m[r,1]])\n",
    "\n",
    "        u, s, vt = np.linalg.svd(A) # Solve s ystem of linear equations Ah = 0 using SVD\n",
    "        # pick H from last line of vt  \n",
    "        H = np.reshape(vt[8], (3,3))\n",
    "        # normalization, let H[2,2] equals to 1\n",
    "        H = (1/H.item(8)) * H\n",
    "\n",
    "        return H\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Blender:\n",
    "    def linearBlending(self, imgs):\n",
    "        '''\n",
    "        linear Blending(also known as Feathering)\n",
    "        '''\n",
    "        img_left, img_right = imgs\n",
    "        (hl, wl) = img_left.shape[:2]\n",
    "        (hr, wr) = img_right.shape[:2]\n",
    "        img_left_mask = np.zeros((hr, wr), dtype=\"int\")\n",
    "        img_right_mask = np.zeros((hr, wr), dtype=\"int\")\n",
    "        \n",
    "        # find the left image and right image mask region(Those not zero pixels)\n",
    "        for i in range(hl):\n",
    "            for j in range(wl):\n",
    "                if np.count_nonzero(img_left[i, j]) > 0:\n",
    "                    img_left_mask[i, j] = 1\n",
    "        for i in range(hr):\n",
    "            for j in range(wr):\n",
    "                if np.count_nonzero(img_right[i, j]) > 0:\n",
    "                    img_right_mask[i, j] = 1\n",
    "        \n",
    "        # find the overlap mask(overlap region of two image)\n",
    "        overlap_mask = np.zeros((hr, wr), dtype=\"int\")\n",
    "        for i in range(hr):\n",
    "            for j in range(wr):\n",
    "                if (np.count_nonzero(img_left_mask[i, j]) > 0 and np.count_nonzero(img_right_mask[i, j]) > 0):\n",
    "                    overlap_mask[i, j] = 1\n",
    "        \n",
    "        # Plot the overlap mask\n",
    "        plt.figure(21)\n",
    "        plt.title(\"overlap_mask\")\n",
    "        plt.imshow(overlap_mask.astype(int), cmap=\"gray\")\n",
    "        \n",
    "        # compute the alpha mask to linear blending the overlap region\n",
    "        alpha_mask = np.zeros((hr, wr)) # alpha value depend on left image\n",
    "        for i in range(hr): \n",
    "            minIdx = maxIdx = -1\n",
    "            for j in range(wr):\n",
    "                if (overlap_mask[i, j] == 1 and minIdx == -1):\n",
    "                    minIdx = j\n",
    "                if (overlap_mask[i, j] == 1):\n",
    "                    maxIdx = j\n",
    "            \n",
    "            if (minIdx == maxIdx): # represent this row's pixels are all zero, or only one pixel not zero\n",
    "                continue\n",
    "                \n",
    "            decrease_step = 1 / (maxIdx - minIdx)\n",
    "            for j in range(minIdx, maxIdx + 1):\n",
    "                alpha_mask[i, j] = 1 - (decrease_step * (j - minIdx))\n",
    "        \n",
    "        \n",
    "        \n",
    "        linearBlending_img = np.copy(img_right)\n",
    "        linearBlending_img[:hl, :wl] = np.copy(img_left)\n",
    "        # linear blending\n",
    "        for i in range(hr):\n",
    "            for j in range(wr):\n",
    "                if ( np.count_nonzero(overlap_mask[i, j]) > 0):\n",
    "                    linearBlending_img[i, j] = alpha_mask[i, j] * img_left[i, j] + (1 - alpha_mask[i, j]) * img_right[i, j]\n",
    "        \n",
    "        return linearBlending_img\n",
    "    def linearBlendingWithConstantWidth(self, imgs):\n",
    "        '''\n",
    "        linear Blending with Constat Width, avoiding ghost region\n",
    "        # you need to determine the size of constant with\n",
    "        '''\n",
    "        img_left, img_right = imgs\n",
    "        (hl, wl) = img_left.shape[:2]\n",
    "        (hr, wr) = img_right.shape[:2]\n",
    "        img_left_mask = np.zeros((hr, wr), dtype=\"int\")\n",
    "        img_right_mask = np.zeros((hr, wr), dtype=\"int\")\n",
    "        constant_width = 3 # constant width\n",
    "        \n",
    "        # find the left image and right image mask region(Those not zero pixels)\n",
    "        for i in range(hl):\n",
    "            for j in range(wl):\n",
    "                if np.count_nonzero(img_left[i, j]) > 0:\n",
    "                    img_left_mask[i, j] = 1\n",
    "        for i in range(hr):\n",
    "            for j in range(wr):\n",
    "                if np.count_nonzero(img_right[i, j]) > 0:\n",
    "                    img_right_mask[i, j] = 1\n",
    "                    \n",
    "        # find the overlap mask(overlap region of two image)\n",
    "        overlap_mask = np.zeros((hr, wr), dtype=\"int\")\n",
    "        for i in range(hr):\n",
    "            for j in range(wr):\n",
    "                if (np.count_nonzero(img_left_mask[i, j]) > 0 and np.count_nonzero(img_right_mask[i, j]) > 0):\n",
    "                    overlap_mask[i, j] = 1\n",
    "        \n",
    "        # compute the alpha mask to linear blending the overlap region\n",
    "        alpha_mask = np.zeros((hr, wr)) # alpha value depend on left image\n",
    "        for i in range(hr):\n",
    "            minIdx = maxIdx = -1\n",
    "            for j in range(wr):\n",
    "                if (overlap_mask[i, j] == 1 and minIdx == -1):\n",
    "                    minIdx = j\n",
    "                if (overlap_mask[i, j] == 1):\n",
    "                    maxIdx = j\n",
    "            \n",
    "            if (minIdx == maxIdx): # represent this row's pixels are all zero, or only one pixel not zero\n",
    "                continue\n",
    "                \n",
    "            decrease_step = 1 / (maxIdx - minIdx)\n",
    "            \n",
    "            # Find the middle line of overlapping regions, and only do linear blending to those regions very close to the middle line.\n",
    "            middleIdx = int((maxIdx + minIdx) / 2)\n",
    "            \n",
    "            # left \n",
    "            for j in range(minIdx, middleIdx + 1):\n",
    "                if (j >= middleIdx - constant_width):\n",
    "                    alpha_mask[i, j] = 1 - (decrease_step * (j - minIdx))\n",
    "                else:\n",
    "                    alpha_mask[i, j] = 1\n",
    "            # right\n",
    "            for j in range(middleIdx + 1, maxIdx + 1):\n",
    "                if (j <= middleIdx + constant_width):\n",
    "                    alpha_mask[i, j] = 1 - (decrease_step * (j - minIdx))\n",
    "                else:\n",
    "                    alpha_mask[i, j] = 0\n",
    "\n",
    "        \n",
    "        linearBlendingWithConstantWidth_img = np.copy(img_right)\n",
    "        linearBlendingWithConstantWidth_img[:hl, :wl] = np.copy(img_left)\n",
    "        # linear blending with constant width\n",
    "        for i in range(hr):\n",
    "            for j in range(wr):\n",
    "                if (np.count_nonzero(overlap_mask[i, j]) > 0):\n",
    "                    linearBlendingWithConstantWidth_img[i, j] = alpha_mask[i, j] * img_left[i, j] + (1 - alpha_mask[i, j]) * img_right[i, j]\n",
    "        \n",
    "        return linearBlendingWithConstantWidth_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "stitcher = Stitcher()\n",
    "img1 = cv2.imread('/Users/zhaosonglin/Desktop/IMG_0912.jpeg')\n",
    "img2 = cv2.imread('/Users/zhaosonglin/Desktop/IMG_0913.jpeg')\n",
    "kps1, features1 = stitcher.detectAndDescribe(img1)\n",
    "kps2, features2 = stitcher.detectAndDescribe(img2)\n",
    "GoodMatchCoordinates = stitcher.matchKeyPoint(kps1, kps2, features1, features2, 0.5)\n",
    "output = stitcher.drawMatches([img1, img2], GoodMatchCoordinates)\n",
    "plt.show()\n",
    "stitch_img = stitcher.stitch([img1, img2], 'noBlending')\n",
    "plt.imshow(stitch_img)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
